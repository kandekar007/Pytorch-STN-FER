{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install scikit-image -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Loading FER data ###\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.is_available:\n",
    "#     print(\"CUDA is available.... 1 2 3...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./FER-2013/train.csv\")\n",
    "df = pd.read_csv(\"./FER-2013/fer2013/fer2013.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['pixelss']=[[int(y) for y in x.split()] for x in df['pixels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixelss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[151, 150, 147, 155, 148, 133, 111, 140, 170, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[231, 212, 156, 164, 174, 138, 161, 173, 182, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[24, 32, 36, 30, 32, 23, 19, 20, 30, 41, 21, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 15, 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage  \\\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "                                             pixelss  \n",
       "0  [70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...  \n",
       "1  [151, 150, 147, 155, 148, 133, 111, 140, 170, ...  \n",
       "2  [231, 212, 156, 164, 174, 138, 161, 173, 182, ...  \n",
       "3  [24, 32, 36, 30, 32, 23, 19, 20, 30, 41, 21, 2...  \n",
       "4  [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 15, 23...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=df[df['Usage']=='Training']\n",
    "df_valid=df[df['Usage']=='PrivateTest']\n",
    "df_test=df[df['Usage']=='PublicTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im=np.array(df['pixelss'][6969])\n",
    "img=im.reshape(48,48)\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "part={}\n",
    "part['train']= list(range(0,len(df_train)))\n",
    "part['valid']= list(range(0,len(df_valid)))\n",
    "part['test']= list(range(0,len(df_test)))\n",
    "train_labels=df_train['emotion'].tolist()\n",
    "valid_labels=df_valid['emotion'].tolist()\n",
    "test_labels=df_test['emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dff, transforms):\n",
    "        'Initialization'\n",
    "        self.transforms = transforms\n",
    "        self.dff=dff\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dff)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        #ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.dff.iloc[index]['pixelss']\n",
    "        X = np.array(X).reshape(48,48,1)\n",
    "        y = self.dff.iloc[index]['emotion']\n",
    "\n",
    "        if self.transforms:\n",
    "          X = self.transforms(X)\n",
    "        \n",
    "        X = torch.cat((X,X,X),0)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,'shuffle': True,'num_workers': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "from albumentations import pytorch as AT\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "#from torchsummary import summary\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "\n",
    "class AlbumentationWrapper(object):\n",
    "    def __init__(self,split):\n",
    "        self.split=split\n",
    "        self.aug=albumentations.Compose([                                         \n",
    "    albumentations.Normalize((0.5), (0.5)),\n",
    "    AT.ToTensor()\n",
    "    ])\n",
    "\t\n",
    "        if self.split=='train':\n",
    "            self.aug=albumentations.Compose([\n",
    "                                             \n",
    "            #albumentations.Resize(48,48),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.Cutout(2,2,2,0.5),\n",
    "    albumentations.GaussNoise(),\n",
    "    #albumentations.ElasticTransform(),    \n",
    "    albumentations.Normalize((0.5), (0.5)),\n",
    "    AT.ToTensor()    \n",
    "    ])\n",
    "            \n",
    "    def __call__(self,img):\n",
    "        #img = np.array(img)\n",
    "        img = self.aug(image=img)['image']\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms , validation_transforms=AlbumentationWrapper('train'), AlbumentationWrapper('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(df_train, train_transforms)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(df_valid, validation_transforms)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "test_set = Dataset(df_test, validation_transforms)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(train_losses,train_acc,test_losses,test_acc, label):\n",
    "  fig, axs = plt.subplots(1,2,figsize=(20,8))\n",
    "  axs[0].plot(test_losses, label=label)\n",
    "  axs[0].set_title(\"Test Loss\")\n",
    "  axs[1].plot(test_acc, label=label)\n",
    "  axs[1].set_title(\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer,scheduler):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(data)\n",
    "    loss = criterion(y_pred, target)\n",
    "    running_loss += loss.item()\n",
    "    train_loss.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    #pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f} running_loss={running_loss} threshold={best_loss*(0.996)}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} le={get_lr(optimizer)} Accuracy={100*correct/processed:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            new_target=target.view_as(pred)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    valid_loss.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    valid_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Net(nn.Module):\n",
    "        \n",
    "    def __init__(self, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        dropout_value = dropout\n",
    "        # Input Block\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) \n",
    "\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 24 RF=7\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "        ) \n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), padding=1 , bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        # TRANSITION BLOCK 2\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 12 RF=20\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        )\n",
    "\n",
    "        # TRANSITION BLOCK 3\n",
    "        self.pool3 = nn.MaxPool2d(2, 2) # output_size =6 RF=32\n",
    "\n",
    "        self.convblock8 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3, 3), padding=1, bias=False),\n",
    "             nn.ReLU(),\n",
    "             nn.BatchNorm2d(512),\n",
    "             # nn.Dropout(dropout_value)            \n",
    "         ) \n",
    "\n",
    "        self.convblock9 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3), padding=0, bias=False),\n",
    "             nn.ReLU(),\n",
    "             nn.BatchNorm2d(256),\n",
    "             # nn.Dropout(dropout_value)            \n",
    "         )\n",
    "        # self.pool2 = nn.MaxPool2d(2, 2) # output_size = 2\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=4)\n",
    "        ) \n",
    "        self.convblock10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=7, kernel_size=(1, 1), padding=0, bias=False)\n",
    "        ) \n",
    "        \n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(8 * 8 * 32, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "        #####################################################\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 8 * 8 * 32)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)            # transform the input\n",
    "        x = self.convblock1(x)     # Perform the usual forward pass\n",
    "        x = self.convblock2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblock3(x)        \n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.pool3(x)   \n",
    "        x = self.convblock8(x) \n",
    "        x = self.convblock9(x)    \n",
    "        x = self.gap(x)\n",
    "        x = self.convblock10(x)\n",
    "        x = x.view(-1, 7)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 LR: 0.0019999999999999983 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.9494938850402832 Batch_id=1 le=0.0020000215288962613 Accuracy=10.16:   0%|          | 2/449 [01:08<4:01:44, 32.45s/it]"
     ]
    }
   ],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "\n",
    "model=Net(1)\n",
    "#model.to(device)\n",
    "epochs=32\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9, weight_decay=9e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(training_generator), pct_start=0.2, div_factor=10, cycle_momentum=False, epochs=epochs)\n",
    "\n",
    "input_size=(3,48,48)\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"EPOCH: %s LR: %s \" % (epoch, get_lr(optimizer)))\n",
    "    train(model, training_generator, optimizer,scheduler)\n",
    "    test(model, validation_generator)\n",
    "    #scheduler.step()\n",
    "plot(train_loss,train_acc, valid_loss, valid_acc, 'Loss & Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
