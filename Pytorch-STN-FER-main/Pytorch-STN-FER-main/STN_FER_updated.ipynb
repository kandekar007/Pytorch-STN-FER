{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install scikit-image -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Loading FER data ###\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "# if torch.cuda.is_available:\n",
    "#     print(\"CUDA is available.... 1 2 3...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./FER-2013/train.csv\")\n",
    "df = pd.read_csv(\"./FER-2013/fer2013/fer2013.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pixelss']=[[int(y) for y in x.split()] for x in df['pixels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixelss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[151, 150, 147, 155, 148, 133, 111, 140, 170, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[231, 212, 156, 164, 174, 138, 161, 173, 182, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[24, 32, 36, 30, 32, 23, 19, 20, 30, 41, 21, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>[4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 15, 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage  \\\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "                                             pixelss  \n",
       "0  [70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...  \n",
       "1  [151, 150, 147, 155, 148, 133, 111, 140, 170, ...  \n",
       "2  [231, 212, 156, 164, 174, 138, 161, 173, 182, ...  \n",
       "3  [24, 32, 36, 30, 32, 23, 19, 20, 30, 41, 21, 2...  \n",
       "4  [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 15, 23...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=df[df['Usage']=='Training']\n",
    "df_valid=df[df['Usage']=='PrivateTest']\n",
    "df_test=df[df['Usage']=='PublicTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im=np.array(df['pixelss'][6969])\n",
    "img=im.reshape(48,48)\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "part={}\n",
    "part['train']= list(range(0,len(df_train)))\n",
    "part['valid']= list(range(0,len(df_valid)))\n",
    "part['test']= list(range(0,len(df_test)))\n",
    "train_labels=df_train['emotion'].tolist()\n",
    "valid_labels=df_valid['emotion'].tolist()\n",
    "test_labels=df_test['emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dff, transforms):\n",
    "        'Initialization'\n",
    "        self.transforms = transforms\n",
    "        self.dff=dff\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dff)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        #ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.dff.iloc[index]['pixelss']\n",
    "        X = np.array(X).reshape(48,48,1)\n",
    "        y = self.dff.iloc[index]['emotion']\n",
    "\n",
    "        if self.transforms:\n",
    "          X = self.transforms(X)\n",
    "        \n",
    "        X = torch.cat((X,X,X),0)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,'shuffle': True,'num_workers': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "from albumentations import pytorch as AT\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "#from torchsummary import summary\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "\n",
    "class AlbumentationWrapper(object):\n",
    "    def __init__(self,split):\n",
    "        self.split=split\n",
    "        self.aug=albumentations.Compose([                                         \n",
    "    albumentations.Normalize((0.5), (0.5)),\n",
    "    AT.ToTensor()\n",
    "    ])\n",
    "\t\n",
    "        if self.split=='train':\n",
    "            self.aug=albumentations.Compose([\n",
    "                                             \n",
    "            #albumentations.Resize(48,48),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.Cutout(2,2,2,0.5),\n",
    "    albumentations.GaussNoise(),\n",
    "    #albumentations.ElasticTransform(),    \n",
    "    albumentations.Normalize((0.5), (0.5)),\n",
    "    AT.ToTensor()    \n",
    "    ])\n",
    "            \n",
    "    def __call__(self,img):\n",
    "        #img = np.array(img)\n",
    "        img = self.aug(image=img)['image']\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms , validation_transforms=AlbumentationWrapper('train'), AlbumentationWrapper('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(df_train, train_transforms)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(df_valid, validation_transforms)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "test_set = Dataset(df_test, validation_transforms)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(train_losses,train_acc,test_losses,test_acc, label):\n",
    "  fig, axs = plt.subplots(1,2,figsize=(20,8))\n",
    "  axs[0].plot(test_losses, label=label)\n",
    "  axs[0].set_title(\"Test Loss\")\n",
    "  axs[1].plot(test_acc, label=label)\n",
    "  axs[1].set_title(\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer,scheduler):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(data)\n",
    "    loss = criterion(y_pred, target)\n",
    "    running_loss += loss.item()\n",
    "    train_loss.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    #pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f} running_loss={running_loss} threshold={best_loss*(0.996)}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} le={get_lr(optimizer)} Accuracy={100*correct/processed:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            new_target=target.view_as(pred)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    valid_loss.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    valid_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Net(nn.Module):\n",
    "        \n",
    "    def __init__(self, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        dropout_value = dropout\n",
    "        # Input Block\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) \n",
    "\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 24 RF=7\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "        ) \n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), padding=1 , bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        # TRANSITION BLOCK 2\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 12 RF=20\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        ) \n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            # nn.Dropout(dropout_value)            \n",
    "        )\n",
    "\n",
    "        # TRANSITION BLOCK 3\n",
    "        self.pool3 = nn.MaxPool2d(2, 2) # output_size =6 RF=32\n",
    "\n",
    "        self.convblock8 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3, 3), padding=1, bias=False),\n",
    "             nn.ReLU(),\n",
    "             nn.BatchNorm2d(512),\n",
    "             # nn.Dropout(dropout_value)            \n",
    "         ) \n",
    "\n",
    "        self.convblock9 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3), padding=0, bias=False),\n",
    "             nn.ReLU(),\n",
    "             nn.BatchNorm2d(256),\n",
    "             # nn.Dropout(dropout_value)            \n",
    "         )\n",
    "        # self.pool2 = nn.MaxPool2d(2, 2) # output_size = 2\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=4)\n",
    "        ) \n",
    "        self.convblock10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=7, kernel_size=(1, 1), padding=0, bias=False)\n",
    "        ) \n",
    "        \n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(8 * 8 * 32, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "        #####################################################\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 8 * 8 * 32)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)            # transform the input\n",
    "        x = self.convblock1(x)     # Perform the usual forward pass\n",
    "        x = self.convblock2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblock3(x)        \n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.pool3(x)   \n",
    "        x = self.convblock8(x) \n",
    "        x = self.convblock9(x)    \n",
    "        x = self.gap(x)\n",
    "        x = self.convblock10(x)\n",
    "        x = x.view(-1, 7)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 LR: 0.020000000000000004 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.5240991115570068 Batch_id=448 le=0.01893656628692835 Accuracy=26.97: 100%|██████████| 449/449 [00:42<00:00, 10.67it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 1350/3589 (37.61%)\n",
      "\n",
      "EPOCH: 1 LR: 0.01893656628692835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.6406059265136719 Batch_id=448 le=0.015997574317068365 Accuracy=36.16: 100%|██████████| 449/449 [00:41<00:00, 10.73it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1708/3589 (47.59%)\n",
      "\n",
      "EPOCH: 2 LR: 0.015997574317068365 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.5101609230041504 Batch_id=448 le=0.011877562566685818 Accuracy=39.42: 100%|██████████| 449/449 [00:41<00:00, 10.70it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 1901/3589 (52.97%)\n",
      "\n",
      "EPOCH: 3 LR: 0.011877562566685818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.6088314056396484 Batch_id=448 le=0.0075501664565825145 Accuracy=40.52: 100%|██████████| 449/449 [00:41<00:00, 10.71it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 2024/3589 (56.39%)\n",
      "\n",
      "EPOCH: 4 LR: 0.0075501664565825145 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.5247586965560913 Batch_id=448 le=0.004038030189713788 Accuracy=42.28: 100%|██████████| 449/449 [00:42<00:00, 10.63it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 2159/3589 (60.16%)\n",
      "\n",
      "EPOCH: 5 LR: 0.004038030189713788 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3432718515396118 Batch_id=448 le=0.0021711369018773768 Accuracy=43.31: 100%|██████████| 449/449 [00:42<00:00, 10.68it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 2155/3589 (60.04%)\n",
      "\n",
      "EPOCH: 6 LR: 0.0021711369018773768 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.391136646270752 Batch_id=448 le=0.001997273042813163 Accuracy=44.14: 100%|██████████| 449/449 [00:41<00:00, 10.73it/s]  \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 2226/3589 (62.02%)\n",
      "\n",
      "EPOCH: 7 LR: 0.001997273042813163 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.2796413898468018 Batch_id=448 le=0.0019807511907248246 Accuracy=44.70: 100%|██████████| 449/449 [00:42<00:00, 10.67it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 2227/3589 (62.05%)\n",
      "\n",
      "EPOCH: 8 LR: 0.0019807511907248246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.2694411277770996 Batch_id=448 le=0.0019494929687730493 Accuracy=45.24: 100%|██████████| 449/449 [00:42<00:00, 10.49it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 2189/3589 (60.99%)\n",
      "\n",
      "EPOCH: 9 LR: 0.0019494929687730493 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.4014192819595337 Batch_id=448 le=0.0019039685297112243 Accuracy=45.31: 100%|██████████| 449/449 [00:42<00:00, 10.61it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 2211/3589 (61.60%)\n",
      "\n",
      "EPOCH: 10 LR: 0.0019039685297112243 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.5115668773651123 Batch_id=448 le=0.0018448626034771058 Accuracy=45.90: 100%|██████████| 449/449 [00:41<00:00, 10.71it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 2234/3589 (62.25%)\n",
      "\n",
      "EPOCH: 11 LR: 0.0018448626034771058 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.471215009689331 Batch_id=448 le=0.001773064198217203 Accuracy=46.77: 100%|██████████| 449/449 [00:41<00:00, 10.71it/s]  \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 2272/3589 (63.30%)\n",
      "\n",
      "EPOCH: 12 LR: 0.001773064198217203 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.4983160495758057 Batch_id=448 le=0.0016896532287767657 Accuracy=46.93: 100%|██████████| 449/449 [00:42<00:00, 10.64it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 2273/3589 (63.33%)\n",
      "\n",
      "EPOCH: 13 LR: 0.0016896532287767657 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3192341327667236 Batch_id=448 le=0.0015958842737753241 Accuracy=47.39: 100%|██████████| 449/449 [00:42<00:00, 10.66it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 2268/3589 (63.19%)\n",
      "\n",
      "EPOCH: 14 LR: 0.0015958842737753241 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.4579006433486938 Batch_id=448 le=0.0014931677055764845 Accuracy=48.40: 100%|██████████| 449/449 [00:42<00:00, 10.68it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 2251/3589 (62.72%)\n",
      "\n",
      "EPOCH: 15 LR: 0.0014931677055764845 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1855028867721558 Batch_id=448 le=0.0013830484769748045 Accuracy=48.94: 100%|██████████| 449/449 [00:42<00:00, 10.64it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 2245/3589 (62.55%)\n",
      "\n",
      "EPOCH: 16 LR: 0.0013830484769748045 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1319756507873535 Batch_id=448 le=0.0012671828836677153 Accuracy=49.68: 100%|██████████| 449/449 [00:41<00:00, 10.72it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 2261/3589 (63.00%)\n",
      "\n",
      "EPOCH: 17 LR: 0.0012671828836677153 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9511611461639404 Batch_id=448 le=0.001147313652026549 Accuracy=50.19: 100%|██████████| 449/449 [00:42<00:00, 10.63it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 2301/3589 (64.11%)\n",
      "\n",
      "EPOCH: 18 LR: 0.001147313652026549 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9432078003883362 Batch_id=448 le=0.0010252437268697782 Accuracy=51.28: 100%|██████████| 449/449 [00:42<00:00, 10.68it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 2294/3589 (63.92%)\n",
      "\n",
      "EPOCH: 19 LR: 0.0010252437268697782 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.2184226512908936 Batch_id=448 le=0.0009028091534947628 Accuracy=51.81: 100%|██████████| 449/449 [00:42<00:00, 10.64it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 2299/3589 (64.06%)\n",
      "\n",
      "EPOCH: 20 LR: 0.0009028091534947628 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.175162672996521 Batch_id=448 le=0.0007818514618474794 Accuracy=52.53: 100%|██████████| 449/449 [00:42<00:00, 10.67it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 2316/3589 (64.53%)\n",
      "\n",
      "EPOCH: 21 LR: 0.0007818514618474794 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3866852521896362 Batch_id=448 le=0.0006641899681980345 Accuracy=53.50: 100%|██████████| 449/449 [00:41<00:00, 10.71it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 2321/3589 (64.67%)\n",
      "\n",
      "EPOCH: 22 LR: 0.0006641899681980345 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1260106563568115 Batch_id=448 le=0.0005515944109305376 Accuracy=54.01: 100%|██████████| 449/449 [00:42<00:00, 10.65it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 2311/3589 (64.39%)\n",
      "\n",
      "EPOCH: 23 LR: 0.0005515944109305376 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.064319133758545 Batch_id=448 le=0.00044575833203052746 Accuracy=54.87: 100%|██████████| 449/449 [00:42<00:00, 10.69it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 2319/3589 (64.61%)\n",
      "\n",
      "EPOCH: 24 LR: 0.00044575833203052746 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.2020471096038818 Batch_id=448 le=0.0003482736046371552 Accuracy=55.80: 100%|██████████| 449/449 [00:41<00:00, 10.70it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 2330/3589 (64.92%)\n",
      "\n",
      "EPOCH: 25 LR: 0.0003482736046371552 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1608355045318604 Batch_id=448 le=0.00026060648978945284 Accuracy=55.78: 100%|██████████| 449/449 [00:42<00:00, 10.64it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 2331/3589 (64.95%)\n",
      "\n",
      "EPOCH: 26 LR: 0.00026060648978945284 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1431193351745605 Batch_id=448 le=0.00018407558249550676 Accuracy=55.86: 100%|██████████| 449/449 [00:42<00:00, 10.66it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 2340/3589 (65.20%)\n",
      "\n",
      "EPOCH: 27 LR: 0.00018407558249550676 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9752162098884583 Batch_id=448 le=0.00011983197883618375 Accuracy=56.19: 100%|██████████| 449/449 [00:42<00:00, 10.67it/s]\n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 2335/3589 (65.06%)\n",
      "\n",
      "EPOCH: 28 LR: 0.00011983197883618375 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0880647897720337 Batch_id=448 le=6.884196240863205e-05 Accuracy=56.76: 100%|██████████| 449/449 [00:42<00:00, 10.64it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 2344/3589 (65.31%)\n",
      "\n",
      "EPOCH: 29 LR: 6.884196240863205e-05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.089098572731018 Batch_id=448 le=3.187247052156096e-05 Accuracy=56.36: 100%|██████████| 449/449 [00:42<00:00, 10.66it/s]  \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 2332/3589 (64.98%)\n",
      "\n",
      "EPOCH: 30 LR: 3.187247052156096e-05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1169662475585938 Batch_id=448 le=9.479558744250297e-06 Accuracy=56.65: 100%|██████████| 449/449 [00:42<00:00, 10.65it/s] \n",
      "  0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 2337/3589 (65.12%)\n",
      "\n",
      "EPOCH: 31 LR: 9.479558744250297e-06 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.152350664138794 Batch_id=448 le=2.00003731321086e-06 Accuracy=57.29: 100%|██████████| 449/449 [00:42<00:00, 10.62it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 2342/3589 (65.25%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "\n",
    "model=Net(1)\n",
    "model.to(device)\n",
    "epochs=32\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0002, weight_decay=9e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, steps_per_epoch=len(training_generator), pct_start=0.2, div_factor=0.1, cycle_momentum=False, epochs=epochs)\n",
    "\n",
    "input_size=(3,48,48)\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"EPOCH: %s LR: %s \" % (epoch, get_lr(optimizer)))\n",
    "    train(model, training_generator, optimizer,scheduler)\n",
    "    test(model, validation_generator)\n",
    "    #scheduler.step()\n",
    "plot(train_loss,train_acc, valid_loss, valid_acc, 'Loss & Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FerDataset(Dataset):\n",
    "    \"\"\"FER dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.frame.iloc[idx, 0].astype('str'))\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'emotion': emotion, 'pixels': pixels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./FER-2013/train.csv\")\n",
    "df.head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/naruto/Desktop/AI/STN/0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4da2547b1373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     print(i, sample['emotion'].shape, sample['pixels'].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-acb15710a95b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                (plugin, kind))\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/naruto/Desktop/AI/STN/0'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "face_dataset = FerDataset(csv_file='./FER-2013/train.csv',\n",
    "                                    root_dir='.')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    sample = face_dataset[i]\n",
    "\n",
    "#     print(i, sample['emotion'].shape, sample['pixels'].shape)\n",
    "\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     ax.axis('off')\n",
    "#     show_landmarks(**sample)\n",
    "\n",
    "#     if i == 3:\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859b42573cde48cabfb16cd1c3916e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e21e1191d2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    transform=transforms.Compose([\n\u001b[1;32m      7\u001b[0m                        \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                        \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                    ])), batch_size=64, shuffle=True, num_workers=4)\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# process and save as torch files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     69\u001b[0m             urllib.request.urlretrieve(\n\u001b[1;32m     70\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_bar_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='.', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), batch_size=64, shuffle=True, num_workers=4)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicting spatial transformer networks\n",
    "--------------------------------------\n",
    "\n",
    "Spatial transformer networks boils down to three main components :\n",
    "\n",
    "-  The localization network is a regular CNN which regresses the\n",
    "   transformation parameters. The transformation is never learned\n",
    "   explicitly from this dataset, instead the network learns automatically\n",
    "   the spatial transformations that enhances the global accuracy.\n",
    "-  The grid generator generates a grid of coordinates in the input\n",
    "   image corresponding to each pixel from the output image.\n",
    "-  The sampler uses the parameters of the transformation and applies\n",
    "   it to the input image.\n",
    "\n",
    ".. figure:: /_static/img/stn/stn-arch.png\n",
    "\n",
    ".. Note::\n",
    "   We need the latest version of PyTorch that contains\n",
    "   affine_grid and grid_sample modules.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        #self.fc2 = nn.\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's use the SGD algorithm to train the model. The network is\n",
    "learning the classification task in a supervised way. In the same time\n",
    "the model is learning STN automatically in an end-to-end fashion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(training_generator):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(training_generator.dataset),\n",
    "                100. * batch_idx / len(training_generator), loss.item()))\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in validation_generator:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(validation_generator.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(validation_generator.dataset),\n",
    "                      100. * correct / len(validation_generator.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the STN results\n",
    "---------------------------\n",
    "\n",
    "Now, we will inspect the results of our learned visual attention\n",
    "mechanism.\n",
    "\n",
    "We define a small helper function in order to visualize the\n",
    "transformations while training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 1, 7, 7], expected input[64, 3, 48, 48] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4b80af195c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-8aeaab324695>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f06b408809c5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# transform the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Perform the usual forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f06b408809c5>\u001b[0m in \u001b[0;36mstn\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Spatial transformer network forward function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 1, 7, 7], expected input[64, 3, 48, 48] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "# We want to visualize the output of the spatial transformers layer\n",
    "# after the training, we visualize a batch of input images and\n",
    "# the corresponding transformed batch using STN.\n",
    "\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "\n",
    "for epoch in range(1, 20 + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# Visualize the STN transformation on some input batch\n",
    "visualize_stn()\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
